{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2412514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-2019 Uber Technologies, Inc.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "\"\"\"\n",
    "This example implements amortized Latent Dirichlet Allocation [1],\n",
    "demonstrating how to marginalize out discrete assignment variables in a Pyro\n",
    "model. This model and inference algorithm treat documents as vectors of\n",
    "categorical variables (vectors of word ids), and collapses word-topic\n",
    "assignments using Pyro's enumeration. We use PyTorch's reparametrized Gamma and\n",
    "Dirichlet distributions [2], avoiding the need for Laplace approximations as in\n",
    "[1]. Following [1] we use the Adam optimizer and clip gradients.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Akash Srivastava, Charles Sutton. ICLR 2017.\n",
    "    \"Autoencoding Variational Inference for Topic Models\"\n",
    "    https://arxiv.org/pdf/1703.01488.pdf\n",
    "[2] Martin Jankowiak, Fritz Obermeyer. ICML 2018.\n",
    "    \"Pathwise gradients beyond the reparametrization trick\"\n",
    "    https://arxiv.org/pdf/1806.01851.pdf\n",
    "\"\"\"\n",
    "import argparse\n",
    "import functools\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, JitTraceEnum_ELBO, TraceEnum_ELBO\n",
    "from pyro.optim import ClippedAdam\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import torch\n",
    "\n",
    "assert pyro.__version__.startswith('1.8.1')\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "smoke_test = 'CI' in os.environ\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a7a59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_word = num_words_per_doc*num_docs\n",
    "#batch_size = num_docs\n",
    "num_topics2 = 10\n",
    "num_words2 = 700\n",
    "num_words_per_doc2 = 100\n",
    "num_docs2 = 7\n",
    "layer_sizes2 = '2-2'\n",
    "learning_rate2 = 1e-3\n",
    "batch_size2 = 7\n",
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce431ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa468d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_topics = 10, num_words = 25000, num_words_per_doc = 1000, num_docs = 25, layer_sizes = '3-3-3', learning_rate = 1e-3, batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "459f9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.INFO)\n",
    "\n",
    "\n",
    "# # This is a fully generative model of a batch of documents.\n",
    "# # data is a [num_words_per_doc, num_documents] shaped array of word ids\n",
    "# # (specifically it is not a histogram). We assume in this simple example\n",
    "# # that all documents have the same number of words.\n",
    "# def model(data=None, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "#     # Globals.\n",
    "#     with pyro.plate(\"topics\", num_topics):\n",
    "#         topic_weights = pyro.sample(\n",
    "#             \"topic_weights\", dist.Gamma(1.0 / num_topics, 1.0)\n",
    "#         )\n",
    "#         topic_words = pyro.sample(\n",
    "#             \"topic_words\", dist.Dirichlet(torch.ones(num_words) / num_words)\n",
    "#         )\n",
    "\n",
    "#     # Locals.\n",
    "#     with pyro.plate(\"documents\", num_docs) as ind:\n",
    "#         if data is not None:\n",
    "#             with pyro.util.ignore_jit_warnings():\n",
    "#                 assert data.shape == (num_words_per_doc, num_docs)\n",
    "#             data = data[:, ind]\n",
    "#         doc_topics = pyro.sample(\"doc_topics\", dist.Dirichlet(topic_weights))\n",
    "#         with pyro.plate(\"words\", num_words_per_doc):\n",
    "#             # The word_topics variable is marginalized out during inference,\n",
    "#             # achieved by specifying infer={\"enumerate\": \"parallel\"} and using\n",
    "#             # TraceEnum_ELBO for inference. Thus we can ignore this variable in\n",
    "#             # the guide.\n",
    "#             word_topics = pyro.sample(\n",
    "#                 \"word_topics\",\n",
    "#                 dist.Categorical(doc_topics),\n",
    "#                 infer={\"enumerate\": \"parallel\"},\n",
    "#             )\n",
    "#             data = pyro.sample(\n",
    "#                 \"doc_words\", dist.Categorical(topic_words[word_topics]), obs=data\n",
    "#             )\n",
    "\n",
    "#     return topic_weights, topic_words, data\n",
    "\n",
    "\n",
    "# # We will use amortized inference of the local topic variables, achieved by a\n",
    "# # multi-layer perceptron. We'll wrap the guide in an nn.Module.\n",
    "# def make_predictor(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "#     layer_sizes = (\n",
    "#         [num_words]\n",
    "#         + [int(s) for s in layer_sizes.split(\"-\")]\n",
    "#         + [num_topics]\n",
    "#     )\n",
    "#     logging.info(\"Creating MLP with sizes {}\".format(layer_sizes))\n",
    "#     layers = []\n",
    "#     for in_size, out_size in zip(layer_sizes, layer_sizes[1:]):\n",
    "#         layer = nn.Linear(in_size, out_size)\n",
    "#         layer.weight.data.normal_(0, 0.001)\n",
    "#         layer.bias.data.normal_(0, 0.001)\n",
    "#         layers.append(layer)\n",
    "#         layers.append(nn.Sigmoid())\n",
    "#     layers.append(nn.Softmax(dim=-1))\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# def parametrized_guide(predictor, data, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "#     # Use a conjugate guide for global variables.\n",
    "#     topic_weights_posterior = pyro.param(\n",
    "#         \"topic_weights_posterior\",\n",
    "#         lambda: torch.ones(num_topics),\n",
    "#         constraint=constraints.positive,\n",
    "#     )\n",
    "#     topic_words_posterior = pyro.param(\n",
    "#         \"topic_words_posterior\",\n",
    "#         lambda: torch.ones(num_topics, num_words),\n",
    "#         constraint=constraints.greater_than(0.5),\n",
    "#     )\n",
    "#     with pyro.plate(\"topics\", num_topics):\n",
    "#         pyro.sample(\"topic_weights\", dist.Gamma(topic_weights_posterior, 1.0))\n",
    "#         pyro.sample(\"topic_words\", dist.Dirichlet(topic_words_posterior))\n",
    "\n",
    "#     # Use an amortized guide for local variables.\n",
    "#     pyro.module(\"predictor\", predictor)\n",
    "#     with pyro.plate(\"documents\", num_docs, batch_size) as ind:\n",
    "#         data = data[:, ind]\n",
    "#         # The neural network will operate on histograms rather than word\n",
    "#         # index vectors, so we'll convert the raw data to a histogram.\n",
    "#         counts = torch.zeros(num_words, ind.size(0)).scatter_add(\n",
    "#             0, data, torch.ones(data.shape)\n",
    "#         )\n",
    "#         doc_topics = predictor(counts.transpose(0, 1))\n",
    "#         pyro.sample(\"doc_topics\", dist.Delta(doc_topics, event_dim=1))\n",
    "\n",
    "\n",
    "# def main(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "#     logging.info(\"Generating data\")\n",
    "#     pyro.set_rng_seed(0)\n",
    "#     pyro.clear_param_store()\n",
    "\n",
    "#     # We can generate synthetic data directly by calling the model.\n",
    "#     true_topic_weights, true_topic_words, data = model(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "\n",
    "#     # We'll train using SVI.\n",
    "#     logging.info(\"-\" * 40)\n",
    "#     logging.info(\"Training on {} documents\".format(num_docs))\n",
    "#     predictor = make_predictor(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "#     guide = functools.partial(parametrized_guide, predictor)\n",
    "#     Elbo = JitTraceEnum_ELBO #if args.jit else TraceEnum_ELBO\n",
    "#     elbo = Elbo(max_plate_nesting=2)\n",
    "#     optim = ClippedAdam({\"lr\": learning_rate})\n",
    "#     svi = SVI(model, guide, optim, elbo)\n",
    "#     logging.info(\"Step\\tLoss\")\n",
    "#     for step in tqdm(range(num_steps)):\n",
    "#         loss = svi.step(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "#         if step % 10 == 0:\n",
    "#             logging.info(\"{: >5d}\\t{}\".format(step, loss))\n",
    "#     loss = elbo.loss(model, guide, data, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "#     logging.info(\"final loss = {}\".format(loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77ae747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data=None, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "    # Globals.\n",
    "    with pyro.plate(\"topics\", num_topics):\n",
    "        topic_weights = pyro.sample(\n",
    "            \"topic_weights\", dist.Gamma(1.0 / num_topics, 1.0)\n",
    "        )\n",
    "        topic_words = pyro.sample(\n",
    "            \"topic_words\", dist.Dirichlet(torch.ones(num_words) / num_words)\n",
    "        )\n",
    "\n",
    "    # Locals.\n",
    "    with pyro.plate(\"documents\", num_docs) as ind:\n",
    "        if data is not None:\n",
    "            with pyro.util.ignore_jit_warnings():\n",
    "                assert data.shape == (num_words_per_doc, num_docs)\n",
    "            data = data[:, ind]\n",
    "        doc_topics = pyro.sample(\"doc_topics\", dist.Dirichlet(topic_weights))\n",
    "        with pyro.plate(\"words\", num_words_per_doc):\n",
    "            # The word_topics variable is marginalized out during inference,\n",
    "            # achieved by specifying infer={\"enumerate\": \"parallel\"} and using\n",
    "            # TraceEnum_ELBO for inference. Thus we can ignore this variable in\n",
    "            # the guide.\n",
    "            word_topics = pyro.sample(\n",
    "                \"word_topics\",\n",
    "                dist.Categorical(doc_topics),\n",
    "                infer={\"enumerate\": \"parallel\"},\n",
    "            )\n",
    "            data = pyro.sample(\n",
    "                \"doc_words\", dist.Categorical(topic_words[word_topics]), obs=data\n",
    "            )\n",
    "\n",
    "    return topic_weights, topic_words, data\n",
    "\n",
    "\n",
    "# We will use amortized inference of the local topic variables, achieved by a\n",
    "# multi-layer perceptron. We'll wrap the guide in an nn.Module.\n",
    "def make_predictor(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "    layer_sizes = (\n",
    "        [num_words]\n",
    "        + [int(s) for s in layer_sizes.split(\"-\")]\n",
    "        + [num_topics]\n",
    "    )\n",
    "    logging.info(\"Creating MLP with sizes {}\".format(layer_sizes))\n",
    "    layers = []\n",
    "    for in_size, out_size in zip(layer_sizes, layer_sizes[1:]):\n",
    "        layer = nn.Linear(in_size, out_size)\n",
    "        layer.weight.data.normal_(0, 0.001)\n",
    "        layer.bias.data.normal_(0, 0.001)\n",
    "        layers.append(layer)\n",
    "        layers.append(nn.Sigmoid())\n",
    "    layers.append(nn.Softmax(dim=-1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def parametrized_guide(predictor, data, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "    # Use a conjugate guide for global variables.\n",
    "    topic_weights_posterior = pyro.param(\n",
    "        \"topic_weights_posterior\",\n",
    "        lambda: torch.ones(num_topics),\n",
    "        constraint=constraints.positive,\n",
    "    )\n",
    "    topic_words_posterior = pyro.param(\n",
    "        \"topic_words_posterior\",\n",
    "        lambda: torch.ones(num_topics, num_words),\n",
    "        constraint=constraints.greater_than(0.5),\n",
    "    )\n",
    "    with pyro.plate(\"topics\", num_topics):\n",
    "        pyro.sample(\"topic_weights\", dist.Gamma(topic_weights_posterior, 1.0))\n",
    "        pyro.sample(\"topic_words\", dist.Dirichlet(topic_words_posterior))\n",
    "\n",
    "    # Use an amortized guide for local variables.\n",
    "    pyro.module(\"predictor\", predictor)\n",
    "    with pyro.plate(\"documents\", num_docs, batch_size) as ind:\n",
    "        data = data[:, ind]\n",
    "        # The neural network will operate on histograms rather than word\n",
    "        # index vectors, so we'll convert the raw data to a histogram.\n",
    "        counts = torch.zeros(num_words, ind.size(0)).scatter_add(\n",
    "            0, data, torch.ones(data.shape)\n",
    "        )\n",
    "        doc_topics = predictor(counts.transpose(0, 1))\n",
    "        pyro.sample(\"doc_topics\", dist.Delta(doc_topics, event_dim=1))\n",
    "\n",
    "\n",
    "def main(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2):\n",
    "    logging.info(\"Generating data\")\n",
    "    pyro.set_rng_seed(0)\n",
    "    pyro.clear_param_store()\n",
    "    tot_loss = []\n",
    "    tot_num_steps = []\n",
    "    # We can generate synthetic data directly by calling the model.\n",
    "    true_topic_weights, true_topic_words, data = model(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "\n",
    "    # We'll train using SVI.\n",
    "    logging.info(\"-\" * 40)\n",
    "    logging.info(\"Training on {} documents\".format(num_docs))\n",
    "    predictor = make_predictor(num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "    guide = functools.partial(parametrized_guide, predictor)\n",
    "    Elbo = JitTraceEnum_ELBO# if args.jit else TraceEnum_ELBO\n",
    "    elbo = Elbo(max_plate_nesting=2)\n",
    "    optim = ClippedAdam({\"lr\": learning_rate})\n",
    "    svi = SVI(model, guide, optim, elbo)\n",
    "    logging.info(\"Step\\tLoss\")\n",
    "    for step in tqdm(range(num_steps)):\n",
    "        loss = svi.step(data, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "        tot_loss.append(loss)\n",
    "        tot_num_steps.append(step)\n",
    "        if step % 10 == 0:\n",
    "            logging.info(\"{: >5d}\\t{}\".format(step, loss))\n",
    "    loss = elbo.loss(model, guide, data, num_topics = num_topics2, num_words = num_words2, num_words_per_doc = num_words_per_doc2, num_docs = num_docs2, layer_sizes = layer_sizes2, learning_rate = learning_rate2, batch_size = batch_size2)\n",
    "    plt.plot(tot_num_steps, tot_loss)\n",
    "    logging.info(\"final loss = {}\".format(loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0a9f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [00:27<00:00, 36.39it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA79UlEQVR4nO3dd5xU1dnA8d8zO9thqUuRBRYEREQBQQQVVEBFSSyJBY3RvMHwWlLUJMYSkxijsSVRE1+NibHFqMQeBY0ioCiCi3Rpi1Rpu/S6bc77x7139s7Ondk7u7Nsmef7+eyHmXPvnTkXlnnmtOeIMQallFIq0NgVUEop1TRoQFBKKQVoQFBKKWXTgKCUUgrQgKCUUsoWbOwK1FXHjh1NYWFhY1dDKaWalfnz55caY/K9jjXbgFBYWEhRUVFjV0MppZoVEVkf65h2GSmllAI0ICillLJpQFBKKQVoQFBKKWXTgKCUUgrQgKCUUsqmAUEppRSQ4gFh2eY9LNiwq7GroZRSTUKzXZiWDBMenQ3AuvsmNHJNlFKq8aV0C0EppVQ1DQhKKaUADQhKKaVsKRkQVm7dRyike0krpZRbygWEpV/v4ZyHP+LxWWsauypKKdWkpFxA2LDzIABLNu1p5JoopVTTknIBodLuKkpLk3DZutIDjVUdpZRqMlIuIFSFQgAEA9UB4YyHZjZSbZRSqulIuYBQUWW1EIKBlLt1pZSKK+U+FavsLqNXv9gUUb5jfxlVIcO9U5dTsq+sMaqmlFKNKuUCQmWM6aZnPDiTj1eX8ORHX/HLN5Yc4VoppVTjS72AUBXyLN9XVhluPZRXep+jlFItWa0BQUSyRGSeiCwSkWUicpddPkhE5ojIEhH5j4jk2eWFInJIRBbaP0+4XmuofX6xiDwqImKXZ4rIy3b5XBEpbKD7pSJGQFBKqVTnp4VQBowxxgwCBgPjRWQE8HfgVmPM8cDrwM9d16wxxgy2f651lT8OTAb62j/j7fJJwC5jTB/gT8D99binuE7s0S6pr7dhx0Fd06CUahFqDQjGst9+mm7/GOAY4CO7/H3g2/FeR0S6AnnGmDnGGAM8B1xoH74AeNZ+/Aow1mk9JNuwwvYxjy35OvEP9tEPzuCbf5ldnyoppVST4GsMQUTSRGQhsB143xgzF1gKnG+fcgnQ3XVJLxFZICKzRGSUXdYNcE/t2WSXOcc2AhhjKoE9QAePekwWkSIRKSopKfFT9YQ8/MFqAGasLKHfHdN4Z/EW9h6uiDjn+hfmU3jrO7W+1qdrSnnwvRXh57e8sojXasxsUkqppsRXQDDGVBljBgMFwHARGQh8H7hBROYDrYFy+/QtQA9jzBDgZuBf9viC1zd+Z8pPvGPuejxpjBlmjBmWn5/vp+p1Vl4V4oZ/fcHP/72IqpChePs+AKYu2err+iv+NpfHZlTnS5pStImbpyxqkLoqpVQyJDTLyBizG5gJjDfGrDDGnG2MGQq8CKyxzykzxuywH8+3y/thtQgKXC9XAGy2H2/CbmGISBBoA+ys2y0l18adh/jH7LWM++NHvsYKPl1TyrtL/QUNpZRqSvzMMsoXkbb242xgHLBCRDrZZQHgl8ATrvPT7Me9sQaPvzLGbAH2icgIe3zgKuBN+23eAq62H18MfGiPMzS6L7fsZcVWq3WwcNPuWs+/4m9zufaf88PPNc22Uqq58NNC6ArMEJHFwOdYYwhvA5eLyCpgBdY3/aft80cDi0VkEdYA8bXGGOfb/nVYs5OKsVoO0+zyp4AOIlKM1c10a73vLImcVc1b9xyKec7Tn6xlz8GKqPJyneaqlGomgrWdYIxZDAzxKH8EeMSj/FXg1RivVQQM9Cg/jDUw3aQ5eZAAPl+3k8xgdTy96z9fUrR+V9Q15VUhrvz73CNSP6WUqo+UW6lcH+6R70uemMP5f/kk4vjug+XUVFEZ8gwU7y3bSuGt77Bhx8FkV1Mppeok5QPCoII2SXutgMfSiUemr/Y8962F1ni6s/ahZF8ZD3+wSscclFKNJuUDwndG9PR/ch2Wyj03Z33E8/+bWczm3YfCr2Xs2bW3vLKIhz9YzfwN0a0JpZQ6ElI+IHTIzWDCCV19nVvbvKePV5fW+hoPvLuS/31+fji2OK95oKwKgMqq2lsIE5+cw5g/zKz1PKWUSkStg8otXWYwjez0NF/nJisx3sHyyvDezuGPfztC+EnY8dlXTWKJhlKqhUnJgNCxVSal+61NcETwHRD8fHv3Y01J9R7ONZdbNI3VF0qpVJSSXUZv/fBU0tOsr+IHyiq5cVxfX9ctrkPyO6WUai5SMiAc1Tabhy4ZBEDv/FZ0aJXp67pFG3cnvS4hbRIopZqIlOwyArhgcDfOHtCF7Ax/3UUNJVRjWKJKp50qpRpJSrYQHI0dDMAaVH76k7XMW2sNFDsD10s27WH+eh08VkodOSnbQmgqjDHc9Z8vw8+dgOBsurPuvgmNUi+lVOpJ6RZCLN8/tdcRe6+aHUT/mreBT4prX8/gZcf+MtaU7K/9RKWU8qABwcOvvjngyL1ZjYgwc2UJ36ljMrzRD8xg7B9mJaFSSqlUpAGhFjeN69egr7+/rDJpr3WgvCppr6WUSj0aEGrxozF9mHC8d2qLYKAOyY1q+O3bX8Y9PqVoI2WV+kGvlGp4GhBsp/Xp6FkeCAiPfedEnrjyxOhjfvJM1NMtryzm4Q+8M6YqpVQyaUCw/fOak+MeDwai/6o8ihrE5t3VO7UlK5+SUkrVpAHBpzSP7qEjtYisrMIKAqX7y+h7x7Rw+d1vf8mbC79m98Fyz815lFIqEboOwadT+nSIKqtIUrK72jhjCK/M3xRR/tTstUfk/ZVSqUFbCC4zfnYGs35+huexzGAaL08eUafXzQgGuO6Mo+tcr7LKkF0H/edSSjUc/YRx6dUxl54dcmMeP7l3B4p+OS78/Lzju8Q8t2ubrPDjv145lOOOyqtzvZyAUNcuqrlf7WDF1r11fn+lVGrQgBDDlP8dyTP/c1JUeUdXZtRHJw5h+W/He17vnoGUmR6gdVZ6netyuMLqMtp9sKJO11/25GeMf/hjX+fe+cZSCm99p07vo5Rq3jQgxDC8V3vOOKZT3HOCaYGYCfJuGX9M+HFmMI3u7bLrXJdlm/fynb9/Vu8xg7cXb671nOc/W1/rOUqplkkDQhJ875RCrji5R/j5irvHc+7A6sVsmcEABe1yADjVY3Daj0+Kd3Cowt8CteLt+zzLF2/SDX6UUrFpQEiC35x/HPdedHz4eVpAIlYxt81JJyMYYPpPT+f/rhja4PW56P8+9SxPxspqpVTLpQGhAaSJEHB9+Dqtg6PzW5GX3fAzffcdruS5Oes4VF4VMRAdTNN/bqVUbPoJ0QACcb6JSz3TXeT43NTnV28u4/53V0R0M6VrC0EpFYcGhGYmN9N/C2PrnsPsOlC9gjk9gXUM60oPhGc3KaVSQ62fECKSJSLzRGSRiCwTkbvs8kEiMkdElojIf0Qkz3XNbSJSLCIrReQcV/lQ+/xiEXlU7K/LIpIpIi/b5XNFpLAB7rVRnDWgc1JfLzeBbT/Lq0KMemBG+HkiYwhnPDSTn/57Ec98spa5X+1IqI5KqebJz9fNMmCMMWa/iKQDs0VkGvBn4GfGmFki8n3g58CdIjIAmAgcBxwFfCAi/YwxVcDjwGTgM2AqMB6YBkwCdhlj+ojIROB+4LKk3mkjWHbXOUlfXZyd4f1P1rFVBqX7I/MZ1UyEl57gGMJHq0p4Z/EWQLfyVCoV1PoJYSzOvozp9o8BjgE+ssvfB75tP74AeMkYU2aMWQsUA8NFpCuQZ4yZY4wxwHPAha5rnrUfvwKMdVoPzVluZtD3QO41p/Vi3h1j+eDm0+Oe1yrTu4Xg9WHvrHB2BNMS+yvddzh5m/copZo+X59WIpImIguB7cD7xpi5wFLgfPuUS4Du9uNuwEbX5Zvssm7245rlEdcYYyqBPUDUhH0RmSwiRSJSVFJS4qfqDeLdG0fx2vWnJO31urXN5o4Jx9KpdRZ9OrWKe25ORpBJp0Xv+bxlz+GoskM1dlCrqAyx51AFe+q44lkp1bL5CgjGmCpjzGCgAOvb/kDg+8ANIjIfaA04/RVeX0NNnPJ419Ssx5PGmGHGmGH5+fl+qt4g+nfJ48Qe7ZL2et3aZkfMPpr+09M902aA1RLokpfleaym7fsig8Rv/vMlg+76L4N++1/Ka7Qelm/ZS9G6nQnWXCnVkiTUqWyM2Q3MBMYbY1YYY842xgwFXgTW2Kdtorq1AFYQ2WyXF3iUR1wjIkGgDdDsPp0yfHYPFd9zbsRzUyP2HZ3fKmbajMxgAL+dadv2lsU85h5fKKus4txHPubiJ+b4e+E62LLnUO0nKaUalZ9ZRvki0tZ+nA2MA1aISCe7LAD8EnjCvuQtYKI9c6gX0BeYZ4zZAuwTkRH2+MBVwJuua662H18MfGiPMzQrH//iTN7+0Wm1nldzXKFPp9ae53nNUCrsmOO5WU+iitbv4r1lWwE45pfv1vv14pm9upSRv/+QqUu2NOj7KKXqx88so67AsyKShhVAphhj3haRn4jIDfY5rwFPAxhjlonIFOBLoBK4wZ5hBHAd8AyQjTW7yNn+6yngeREpxmoZTKz3nTWCznlZdPbZneP41w9Ojtn99OfLh7DjQDnrSw/w+Kw1fLy6lGO75rFjf/13R7v6H/MAWPTrs+v9WrVZttnKobRgwy7OO75rLWcrpRpLrQHBGLMYGOJR/gjwSIxr7gHu8SgvAgZ6lB/GGphOOacc3THmsaz0NLq1zaZb22wenr4agFaZwYiAMOm0XsxcuZ01JQfq9P4/nbKwTtcppVoeXancTDhTSHMzg7TNqd5b4cdj+5IRjJ6K+sq1I8OPJ8T5Vv7B8u1JrKW35j+BWKnUoAGhmSiz00hkp6dFDDhnpAXwGm5xj1NkNODWmyX7ysJ7PpdVVsXd1c2pZlXIEKrj7m9KqYajAaERxfvmXpMzTTQ7I4022dUthGCaEPIKCK6B52Stlr7j9SVRG+icdM8HXP/PLwBrcPr6F+ZHXSf2rGKnlkffPpWr7DEMpVTT0fC5mJWnVb87N6HcQk6XkfPh/tTVw3jm03UEA+L5rdy9hWeyWggvzN0AwHdH9ATgiVnWTOPpK6q7nd5bti3qOq8uo9nFpUmpk1IqebSF0EgygoG4abJrumiItai7fW4GAGOP7czzk05GRPDqfXGnqfC7PiIer6Bz37QVCb1G85tIrFRq0RZCM3HzWf344Zg+ZKVHDyB7fVi71yokY2OcnQfiT3X9l916UEo1X9pCaCYCAfEMBhAZELq1zeb33zqeNFc/TTK2ztxzqDogXP/CfOatjVxIfvvrS+r82jv2l+neC0o1ARoQWgD3oPKEE7py+fAeES0E9+Nxx0aufh7QNY9HJg6u9T0qqqrfY+qSrVz618TTXNRM0eEY+rsPuKwOr6eUSi4NCC3AzWf1Cz92pqBGdBnFmXHUPjeDcwdWz3a6eGgBXm6essh3fZ6avTbiebxM5qu27QNg0aY9vl9fKdUwNCC0AJcM6857N44GCKeGcAeBNNcA85X2DCGHwZARDPDwZYP5+JYz6dUx1/M9lm/Z67s+d7/9pWe516Dy2X/6KLpQKdUodFC5hTimS+uIXc1itRBGHh25zYTzIX2hPYupGeYUVEoliQaEFsodEHJibLsJ0d/akxUPQiFDeVWIx2euYdfB6gFpzXiqVNOlAaGFcgeEVplB/vG9YRR2iO4OijXQW193vLGEF+dtjCgrqwzxk5cWNMj7KaXqT8cQWqhgoPqfNjMYYEz/zvTOt7bnHFTQJnyssioyICQrPLwyf1NU2YvzNkQsopu5MrHEeht2HGT68uiV0Eqp5NCA0EK54kHULJ8XJ4/ggYtPACJ3TgM88yLVRaxNf9xrJm57LbG1C2f+YSaTni2qV72UUrFpQGih3C2EmuvScjKC9LZnE5VXeQeArPT6/WqU7o+9faejZvD566w1cQe142VSVUrVnwaEFsodBDp57OKWnWGteq7ZQnA+j7NjrIr2y19AiHz++2krWKzrEZRqNBoQWih3N9Hg7m2jjjsf+FEBwf4z1swkd+rtePz0PHm1Bp75dF3E86Vf76HvHVPZsudQuOz0B2ew52CFr3oopfzTgJCinJTYFZWRAeGyk7rTs0MO3x3Z0+sy3rjh1KTVodRjb+jXF3wd8fyfn62nosowc2VJuGz9joN8tLqEtaUH2H2w/vtLK6UsGhBasF+M78+bMT7AnZTYNccQurXNZtbPzwyPMdRU29jCqt+dW4eaxuY0IlZu3RdRXlYZ4syHZnLeIx8n9f2USmW6DqEFu+6Mo2Me69gqk4uHFoQ3u6kpVmZV92C1l/puxtO1jTXeURUyEeMga0r2R5znbNu5ec/hcNnUJVvo36V1eHqtUioxGhBSVCAgPHTJoJjHY227mYxU2vEIcLiiiv53vstPxvYNl3+8OnKHtcMVIWq6/gVrK093Cg+llH/aZaQ8xctQ2lB6dczlQHkVew9bA8YvzF0f89z1Ow6EHzvnK6XqRwOCiqt3fi6XDivg+6f2AqqnqwK0zUmnVabVyDxrQGf+csWQOr/PD0b14tyBXThYXunr/OfmVAeLq/8xr87vq5Sqpl1GypOzd/Povvn85vzjMMZwx4RjI3IkLfzV2Xz78U+Zv34Xk0f35qTC9vV6z9zMIBVVhjKP7qB4FmzYXa/3VUpZNCAoT306teL160/huKOsvEcigrOtwiMTB3Ow3BrUdeJDKAmriHPs1kd1F5D/biu/abuLt+9n1qoSJp3WK9HqKdXiaZeRimlIj3aes4YuGNyNy4f3AKrHGtwfx7+ccGzUNWP7d6J/F+/8RmBNL821F8PtOWQFhNL9ZbxctDHmNW7utBZLv97DnkMV/On9VZTXWGdx0WOfcPfbX0alwXj58w1s3HnQ13sp1VJpC0HVS7iF4PqGnt86M+o8EWHcsZ1ZYa8nODo/lzUl1QPD7XIzyMm0WwiH/I0juOtQ5Xr/b/x5dvhxh1YZXDWyMPx8X5n12kffPpUfj+3LzWf1o6yyil+8uoSAwKOXD+EbJxyV0Psr1VLU2kIQkSwRmScii0RkmYjcZZcPFpHPRGShiBSJyHC7vFBEDtnlC0XkCddrDRWRJSJSLCKPiv31UkQyReRlu3yuiBQ20P2qJLvI3mnNvddCrLUKgYA7nUY7fjCqutvmB6N6h1sIyzYnls8oLSAxE989On11zO6kR6ev5uvdh3hvmZVSO2Tgh/9awOGKqoTeX6mWwk+XURkwxhgzCBgMjBeREcADwF3GmMHAr+znjjXGmMH2z7Wu8seByUBf+2e8XT4J2GWM6QP8Cbi/7rekjqTLTupB8T3nclTb7HCZM/Ccm5FGt3C5iVjDYDCccUwnAE45ugMZwUB4DOHPHxYnVIeKKsPqbfs9j5XuL2fBxt0xrz334Y/48YuRm/ZoQFCpqtaAYCzO/7Z0+8fYP3l2eRtgc7zXEZGuQJ4xZo6xvrI9B1xoH74AeNZ+/Aow1mk9qKYvmBb5a5Rujz53zsvirvOPA6wxAvcMpevPODoqAV5uZt17MK95LvY+CTU3AXLbezi6e8oZMFcq1fgaVBaRNBFZCGwH3jfGzAVuBB4UkY3AQ8Btrkt6icgCEZklIqPssm6AexutTXaZc2wjgDGmEtgDRO4Gr5oN54PfAE5YN1Svcr58ePeIDXScc+oTEEr2xU63nZbg6moNCCpV+QoIxpgqu2uoABguIgOB64CbjDHdgZuAp+zTtwA9jDFDgJuBf4lIHt5zCJ2vbvGOhYnIZHu8oqikpMTjEtUUpKdF/1oZY8IfzNUzk6x/YqG6i6khJJpuY/W2fYRChj++v4odtezrsG3vYTbs0NlJqmVIaNqpMWY3MBOr7/9q4DX70L+B4fY5ZcaYHfbj+cAaoB9Wi6DA9XIFVHczbQK6A4hIEKsLaqfH+z9pjBlmjBmWn5+fSNXVEeR88Genp0W0EJzy6plJ1p/OOTn1aCH4qY9f173wBQ/+dyWPTl/N7a/H3+bz5HunM/rBGfWpnlJNhp9ZRvki0tZ+nA2MA1ZgfZifbp82BljtOj/Nftwba/D4K2PMFmCfiIywxweuAt60r38LK8AAXAx8aPyuNFJNjjPjJy87GP72bwwExAkI1p8dW1mroZ31CYns0jbu2M5x1zV41ScRj89cA1hptv2qrArx+bqo7zFKNRt+vpJ1BZ61P+QDwBRjzNsisht4xP5Gfxhr9hDAaOC3IlIJVAHXGmOc/yXXAc8A2cA0+wes7qbnRaQYq2Uwsb43phrPPnulceusdE7t05GLhxZw47i+zFixHaj+gD7uqDa8cu1IBtk7uiXyTf7vVw8DoPDWd2o9d92OA5TsK2PcgM6J3AZQHbxqU14Z4i8zinl0+mpevW4kQ3vWL42HUo2h1oBgjFkMRGUtM8bMBoZ6lL8KvBrjtYqAgR7lh4FLfNRXNQPtcqxv/ifaK52dNNt59vabuw9VZycdVs/8R3785KWFACy765yEr/Ubo3YeKA/v2fD17sMM9d5mQqkmTVcqq6Q7uXcHXr1uJEO6t4sodwJFY217ub4Og78fLN/OvsMVtM6Kv5d0RVUovAtdzW1JlWouNJeRahBDe7aPWJkMViptgGFxulPe+mFiezZPOKGr73O37T1c+0kebn99KYW3vsMbC77mk+JStu6Jfp3KkAkHhOKS/RTe+g4LNuyq0/sp1Vi0haCOmIJ2OXxy6xi65GXFPKeVa6ZRMCBU1jIg/NgVJ3L2gK/D3ULxbK1jQPjPImsy3DOfrmPhxt20z83gizvPijinKmRID1oB8MPl1ljJK/M3MaRHZCtJqaZMWwjqiOrWNjvu4HGrrOqAsPSucxjQNS/i+MOXDY7Kpup3dlJpnMVrfjipNXYeiO7yqgqZ8PqLipDVZRQrlBljovaIVqop0ICgmpTWmdV99VnpaUz9ySguGFydfXT8wC5cM6p3xDVZPgPCH95fVa+6xXufylD1GIKTKiPWzOl/F21i7B9m8UlxqedxpRqLBgTVpGSlR/9KOqkkfjG+v+eHcnaNFc7uAJJMNVc8uz/w3S2Eyiq7hRCjibBo024AXv7c314PSh0pGhBUkyIi/PSsfrx63SnhMmef5YHd8jyvqTmr59Jh3eO+R2GHnDrVbdW2feHHD763gl63TQ0/r4zoMnJaCNaxRRt384/Za8PnOnHirUVx80EqdcTpoLJqcn40tm/E8zOP6cQnxTvond/K83x36u17LzqeU/t0jPv6fruYalrnmrb62Iw1EceqQoagneXVWXjnbBp0wWOfAPB9e9tOXYOvmioNCKrJm3RaLy4Z2p02Od5rAQo75rL0rnMiZijFk1nHgBBPZZUJB4KKqviDyu4jxphwsr/62nOogrKKKjrFmcWlVDzaZaSaPBGJGQwcfoMB0CBf0atCJjxF1gkIoRrv8/LnG6LePpFcSbU57f4PGX7v9KS9nko9GhBUi3TVyNi5I+J9g040M6qjMhQiZAeE8Id8jbjzi1etzKnugHDuIx9TvH0fybDPY7MfpRKhAUG1SL+9YCCzf3FmVHleVpD2dgoNLwGBmT87I+H3c7cQnA98r3bI1CVbOOjaonNt6QHG/fGjWvddUOpI0ICgWqxOrbPo0T5yRpExEIjzW19RZcgIJv7fojJkqApFdv/U7DICuP6FL8Irn92mLd2a8HsqlWwaEFSLlREM8NEtZ0asbK7yMYib3zoznJLbL3cLwWEMbNzpL6FefuvMhN5PqYagAUG1eO6VzfdedHw4pfXt5/Xnj5daqbk75FZ3I6WnBXjzhsSS7FWGTHgMwREyhkv/OsfX9f8u2lT7SUo1MJ12qlLC85OGU9ghl+7tc/jCzkKakRYgJ8P6L9AqK8gOjxxFflWFQlEthKJ1u3wn1Ptg+bbw49mrSyndX8aFQ7rVuT5K1YUGBJUSRvWt3oPb2QXN/fntBAZ3SyER/y7axKdrdkSU1TW76pVPzQXwDAin3vchk0f35upTCsNlxhjeW7Y14nmy1jao1KIBQaUcZy/mnh1yOFxhDQT3aJ/NiN7tuXpkYZ1es2YwaChf7z7Er99axql9OpCbGaRrm2w+XLGda//5Rfgca2BcA4JKnI4hqJRz2UndeeuHpzL22M5U2jODMoJp/Pqbx1HYMTd8XvE953JhAyXKqwv3GMW4P37EyN9/CMDmGhv2OAvjlEqUBgSVckSEEwraAta3aYB0jwVpwbRAxP4MDW3Omh2UVVavUZhSFJkNtSLk/UG/Znvk3gqPTF+d/MqplKABQaU0J1W1k5iuprwaeynP+vkZngveHA9cfEKd63L53z7jjteXhp/f8sriiONO8HKbuXI7z3y6LqLsX3M31LkOKrVpQFApzUlVHUzz/q+Qlx0ZEHIzg3RzZVetqU8n74ysfs1eHblpzo9eXBB+XOnRFfS9pz+PKnNnc7311cU89N7KetVJpQ4NCCqlOR+yXl1GEN1CyM0Ixp3B0zY7fhI+L73zq8ctas5Mcq9q9moheMnOqP5v/dLnG/nLjOKE66RSkwYEldKc7S5jtxCsMYTCDjk8/b2TonZnA/jpWf3CjxPKumo7tqv3xj+Ov330FdOXb2PDzgO+Xu+0PtYU21hbeDr2Hq5gf5kmxFPVNCColHZ8QRsARvbu4Hm8U2srM2paQDizfyfPc9wb+mR5BAyAF38wImYdylzJ7rzcM3U5k54t4tuP+1v17DRg3B/205ZsYV1pZEA54Tf/5ZTfa7psVU3XIaiUNqJ3BxbceRbtYixI697eGi/wu4o522PznX6dWzHyaO+AA5Cdkdz/hmX22gp3QLjuhS/ISAuw6p5zI87dqymzlYu2EFTKixUMoLqFcLOrWyiedFfX05PfHQpEroj2css5x/h6bb/K7XGRDTsOepYDEdNbwUrOd/fbX1J46zvc8fqSpNZHNR8aEJSKIy0grLtvAlf5WMFcM9X20J7tABjr0dW0/Lfjw4/b5qQzyd5vORn+s2gzz3+2nsue/CzmOb+oMaX1iw27eGr2WgBecE1b3X2wnIfeW+k5w0m1PNplpFQ9OFlRv7jzLLLSI79fdWiVydzbx9KxlZXaumOrDEr3W11P7j0XgoEAd35jAP/8bH3SttS8842lnuVOnqM3FkbuyVAVoxlz79TlTCnaxLFd85hwQtek1E01XbW2EEQkS0TmicgiEVkmInfZ5YNF5DMRWSgiRSIy3HXNbSJSLCIrReQcV/lQEVliH3tU7Pl7IpIpIi/b5XNFpLAB7lWppPnuiJ7cfl7/8L4J7XMzwgny3DrnZYW35Xxp8shwuXurTmdRXANs9RxlToycS7Heu9wOUDW7mFTL5KeFUAaMMcbsF5F0YLaITAN+C9xljJkmIucBDwBniMgAYCJwHHAU8IGI9DPGVAGPA5OBz4CpwHhgGjAJ2GWM6SMiE4H7gcuSeqdKJdHdFw6Meaxrmyz6dm4dVd6nUytW/e5c9hyqiCgP2sHBeG66mVylB8o9p6Ne/8J8z/Od6biVVYYX5q7n+TnrmfaTUZ5rMf70/ipG9e3IsML2ya20OmJqbSEYi5MsJd3+MfaPM4G6DeC0QS8AXjLGlBlj1gLFwHAR6QrkGWPmGOs38jngQtc1z9qPXwHGitdvnFLNwJzbxvLc94d7HssIBqJ2R3N+1Y9EC6GyKsSJd78fUfb8nHXsOljheb4TrCpDhjteX8qKrftYU2JNXy3dX8aaEuujoayyikemr+biJ/xNjfWyats+Cm99h/nrd9b5NVT9+BpUFpE0EVkIbAfeN8bMBW4EHhSRjcBDwG326d0Ad1auTXZZN/txzfKIa4wxlcAeIGqenohMtrunikpKSvxUXalmwysevHvjqKS+R0VVKOrD/843l8U83+nOqgyFwoFs90FrHOS0+z9k7B9mAbBjf/W03H53TGP0AzPYleCGQx+u2A7Ae8u21XKmaii+AoIxpsoYMxgowPq2PxC4DrjJGNMduAl4yj7d65u9iVMe75qa9XjSGDPMGDMsPz/f4xKlmq+aXTnPfX84/bvEX8WcqF+8mtiU0mCgusvoULk1juCk0HD2kgDYvq8s/Li8KsSGnQd5LMGUGc54RUaMVeOq4SX0N2+M2Q3MxOr7vxp4zT70b8BpI28CursuK8DqTtpkP65ZHnGNiASxuqC03ahSSs1vQOk1Phhfmhx7tXNDCIUM739pfVtfvGl3eKGb14wkp9XgVpVgH5gzcJ0Z1IDQWPzMMsoXkbb242xgHLAC68P8dPu0MYCThP0tYKI9c6gX0BeYZ4zZAuwTkRH2+MBVwJuua662H18MfGhqS8SiVAvj/MZ/cusYfnZ2P0b0tgZn594+lk9uHcOIGOk1GsLa0gO89PlGvt59CIA5X1XPTvLal8FruqxX4NixvyzmGIGzwjozXQNCY/Ezy6gr8KyIpGEFkCnGmLdFZDfwiP2N/jDW7CGMMctEZArwJVAJ3GDPMAKrm+kZIBtrdtE0u/wp4HkRKcZqGUxMwr0p1Sx1bp3JD8dU50fqnJcVdU6P9jls2HkwqjxZznxoJhe59nTe70px8d9l2zixR7uI8712aav0CAgXPzGHtaUHWHffhKhjzkpq7TJqPLUGBGPMYmCIR/lsYGiMa+4B7vEoLwKi5usZYw4Dl/ior1It1kOXDOLPH66OWKMQyxs3nBqeLXT7ef25d+qKpNfn9QVfhx8fdCXge3HeBjbWCEblHi2EkEdAWFsaO2NrdQvBO0GgangaipVqIi4eWsCsn58Zd78FR3tX/qXJo49uyGoB0VNii2ts2+kVEOLt3+AVLLSF0Pj0b16pFJQZDNRp7wZHzY18yj26jKpi7AEN3gPOXkFFHVkaEJRKQXdfODAq91JdVYWM54d5vA3evM6vtAPILo8ZS+rI0ICgVDPy9o9O45+TTg4/r7nq+bZz+/PejaNrfZ2MtICvrik/tu87TMn+sqjyeC2ESc9G7wXt7F73u3eWs2TTHgAWbNjFwF+/x84ai9xmrSrhy81761Nt5UEDglLNyMBubTitb0cApv1kFO/+xFrJ/L1TCgFr7cIxXSLzKJ1UGDkjCKwVyLVN7L5qZE9fdRr5+w/566yvosor4zQRPvsqeupphWtc4duPf8rKrft4fOYa9pdVMm9tZFK+q/8xj/Me/dhX/ZR/GhCUaqaO7ZpHBzu1dsD+th/y+JT3Sja3dc/huN/gAU7uVb91D7FSasc+v7o+5VUhHnxvpeu+6lUV5ZMGBKVaAGdijldA8HJyrw5Rawlq6pyXGbEWISfGftGxJLpSuWaLoqBddniaqvNSfW6fyt8+im6NqOTQgKBUC3BsVyvnUa+OrWo9d919Ezi+oA2PXh61vChsUEEbhvZsx58uG0y3tta+0lkJrg9ItIVQcyHb7OJSVm7bB1ipwatChsqQ4Z6pyxN6XeWf7pimVCO556KBpAeS853soiHd6N8ljwFHWYFh3X0TKLz1nbjX5Lqmnb5xw6lc+NgnAFw4+Cju/dbx4UFnZ6FcdoIBwZlJ1O+X0+jaJovffPM4z/O27jnMI9NXhZPnOXa4BqqN8V4NrZJLA4JSjeQ7J/sbtPVDRMLBIOqY/Wen1plMHt076nj39tkMtnd+A3h4YmTLwUmRkWh6scN2QCivDLF+x0H+55nomUUAt7++JJz62q19bkY4VbfBe63DB19uY0iPtuGxFFU/GhCUShFXn1LINaMiA8KCO8/ynUyudL+/9QGXDC3gvWVbOVxexZTPN9Z6fqxv/u4uJ2MMFR5rF655roiB3fJ4+0fJ3TciVekYglIprF2MvaC9+F3IVtAuhzP7d2Lltn3c8urimOed+dBMDpVXxZye6t5vAWKnwliz/QC/fnMpby782vO48k8DglIporYun4Hd8jh7QOeYx9PTAvTrXPugdUYwQFaw9vGGtaUHWFt6IObg88Hy6gyrIWNitiRCxvDsnPX85KWFtb6nik+7jJRSAL66XdJ8DIJnBgO+WxMZwYDn/goAe10pt43x3nMBIqfafvDlNsbFCWoqPm0hKNXCJSlDBSLV6x285NrrFDKCAYI+M5aWV4ZY+vWeWs+rCsVuIbhbGHe/82XEsf95eh6/eSv2ntG1WbRxN9OXp84ezxoQlGrhLh3WnXY56VwwuFvtJ9ciVgvhvOO7cM7ALoDVQvC7BuGlzzfETZPtmLpkS8xsqO63KmiXHXFsxsoSnvl0na+6OIq37w8HqQse+4RJzxYldH1zpgFBqRauZ4dcFvzqbLq3z6n3a6W5WhvDXSkxHpk4JPyBnZme5nvF9LtLt/o6b8bKEi6w10nEE3A1h+qSTvuV+ZsY98dZfOPPsxO+tiXQgKBUC/Xzc44JJ72rj+rPWCHoaiHc+Y0BgNVVlJ4WCPfxJ9JC2L4vOktqfazfcZDHZhRjjGHHgcRf+2f/XpTU+jQ3GhCUaqFuOLMPvznfe3VwIp77/nAAggGhQ6vqndraZKcDcOu5/QFol5MeLk80bUWybNh5kAffW8n2fWVRK59V7TQgKKXicloFaQHhvm+dEC7PCAZYd98EvjuyEIBfffM47v/28Zzcq31UQDi+W5vw43hTW5Nlf1klRet3Nfj7tDQ67VQpFVfQHjgIBKBNTjp5WUH2Hq6k5vhyq8wgl53UAyBqvMLJh3Sk/OG/K5m6JHJ8Ys8hKw3GlM83MnftDv5+9UlHtE7NgQYEpVRczod5mjiBIfK5l+vPOJqB3fLICqZx48sLueWcY7ji73MB75xEXv58+RB+9OKCOtW55gY8Yx6ayVd2Km0Vm3YZKaXicjKyOoHAz3f9YFqAMf07c0qfjsy7Yxy98nPDx/xmLf3moKMSrquj5pabXsHgkQ9W1/n1WyoNCEqpuJyuIadF4HQHJdINlO5aqFZRGTm+cL7rg/+lySMijmX4XOBWF4/NLI54Hqox7lFW6X9QetOug8xfH70taHOjXUZKKV+cAPDU1Sfx2Vc7aJuTUcsV1dwBoeZOas4AdJvsdI7tEpnCe85tY/jvl9u47bUlda12bHY1bnp5IT075DCqb37E4WtcC9JCIcPjs9YwqKBteE9rt1EPzMAYax+K5kwDglIqLifVkBMQ8ltnJtydk5cV5H9P7823hhRw99uR6SWcLqSAEDVQ3aFVZng3OEf39tls3Hkooff3YuyI8PoCK0vqwzW6kD5eXRp+XGUMD763EoDJo3tz+3nHRr5WC9nzWbuMlFJxOd/o6zNTSES47dxjOaZLa7Jr7M3stBBExPM9BhW04b5vHR9+/v5NpzPr52fUuS6OUX3zfa+XcKfo/sfstRHH3GMidVkd3ZRoQFBKxdUq0/oA79Op9tTXfuRlpUc8v+08a2Fb9/Y5EaknHCLCxOE9ws/T0wIRgaNtTnrUNX5kZ6T5HuCudGVkzQwG2HWgnOVb9gLQ945p4WM3vly3WVFNRa0BQUSyRGSeiCwSkWUicpdd/rKILLR/1onIQru8UEQOuY494XqtoSKyRESKReRRsTdtFZFM+/WKRWSuiBQ2zO0qpRLVp1Nrnvv+cO696PjaT/bhtvP6M/Gk7hGv/8SVJ/KPq4f5aoWkBSJbEndOGFCnepRVVPmeAjvpmerxhIxggG89/innPvJx1Hk11z40N37GEMqAMcaY/SKSDswWkWnGmMucE0TkD4A7h+0aY8xgj9d6HJgMfAZMBcYD04BJwC5jTB8RmQjcD1zmcb1SqhGM7pdf+0k+dWyVyX3fPoGXXNtrjh/YFYie6ROLOyC0b+V/cNvto1Wlnttyepm3rnoGUUYwwFp7GuuUotq3CG1Oam0hGMt++2m6/RP+V7O/5V8KvBjvdUSkK5BnjJljrK2bngMutA9fADxrP34FGOu0HpRSqcNZ6/DjsX3jnudeFGeM4dXrTkn4vcqrQmzefTjh69zjDre8EnuL0ObI1xiCiKTZXULbgfeNMXNdh0cB24wx7iH6XiKyQERmiYizDVM3YJPrnE12mXNsI4AxphKrtdHBox6TRaRIRIpKSkr8VF0p1cysu28CN5/VL+457qyroRAM7dmOYT3bJfxedcmIWrq/PO7x3QfjHwcrjUZjJQCMx1dAMMZU2V1ABcBwERnoOnw5ka2DLUAPY8wQ4GbgXyKSh/cCR+dvJN4xdz2eNMYMM8YMy89PXhNWKdX0vfPj0/jz5UOAyOmpzt4LgQRmQT12xYkAfO/pz5NXQZuTMwlg2eY93PbaYna5Vk6XV4YYdNd/+dWbS5P+3vWV0CwjY8xuYCZW3z8iEgS+BbzsOqfMGLPDfjwfWAP0w2oRFLhergDYbD/eBHR3vWYboPkv+1NKJc1xR7UJr3+IaCHYAcFrxpB7b+feHavTZ7TOarglWO56PDajmBfnbWS+K/PqW4usj73Xvvi6wepQV35mGeWLSFv7cTYwDlhhHx4HrDDGbKpxfpr9uDfQF/jKGLMF2CciI+zxgauAN+3L3gKuth9fDHxojzMopVSUyBaC9eeuA9FdNT8aUz0WkRGsviinxlqIZHJvCbr3UCUAlSHDtr2H2bz7UHgTHieQfbqmlJteXsi60gM09seenzDZFXjW/pAPAFOMMW/bxyYSPZg8GvitiFQCVcC1xhjn2/51wDNANtbsImcC71PA8yJSjNUymFi321FKpQJ3C+HUPlYqiY27olcvZ7qCgBMQju2aF7U4Lpnci9iccYKQMZx87/SI85zP/iv+Zg3Jvr7ga+4471h+MLp3g9WtNrUGBGPMYmBIjGPf8yh7FXg1xvlFwECP8sPAJbXVRSmlwEpz4XB2bvMapHXnUDruqDYs3rSHXh1zyMnw12V0ap8OfFK8I6G6udc2OKu8S/dHD1577Tv92Vc7GjUg6EplpVSz42dW+vs3jaZLmywALh/endF2UrpQCHIza28hdM7L5J+TTk64bpVVIQ5XWJlS5621Okd+9eayqPO8AkJj04CglGoR8ltnRjzv27k1Zw/ozBNXDuXuCwbixJCQMbTzkan1T5cN9hV4oq77YBX973yXT9eUxj3PKxx4vd2Xm/fy1qLNbNlT/4R+tdFsp0qpFuGDm06nrKqKz77aSVe7ZSAijB/YJfwYrEHodB/7LHRqnRXz2M1n9eOP768CIDcjjcz0tPCmPM5ubVM+j7+K2RgovPWdiLIPV2xnXekBCl0zos57tDpFxuvXn8KQHomvt/BLWwhKqUaRnZ5Gzw45tZ8Yx4k92oYft8lJp1PrLM4fdBQnFbaPOtdJnBdrJk+nGi2MeMn82uVWtzBEhC/uPIv//PC0iHPeWLi55mW1Chk446GZACzZtCcqYFz0f5/W2vKoD20hKKUaxdK7zqnX9XNvHxuVOTUeJyuqM65w94UD2bz7EHlZ6dz/7oqITKu1JdnLdc1Scs4MpiU3284bC73XKdQl3YZf2kJQSjWKmllLE9U5Lyuh6aMnFbbn0cuHcOc3rOyo3x3Rk1+M78+VI6zU2k7XEkBOevXr3jQuOo2G1ywlP91QydCQaxW0haCUShnne+z01jornfm/HEeb7HSe+XQdAK9dX50sb2C3vKhrvAJRepJbCI0xCUkDglIq5XVoFT1DyeHuSgqIMyjt+vC3HwaT2EI448EZrNtxMGmv55d2GSmllG3Gz87gxR+MiChzTwV1gkMwEKB/l9YR53nt5XD3hVHrcH2JFwwasuGgAUEppWy9OuYy8ujIzPtOEDjNTpEB1gDyk98dFnFeXnbkAPcfLx0UsTNcc6ABQSml4siyB5hbZwXDA8fpgQBpdreR04Bok53OHy8dBEC7nHS+dWJBxEY+zYEGBKWUiuOkwnbccd6x/P5bx4fTaacFxPPD3lnMdqDcSl2RyB4NvjVgn5EGBKWUikNE+MHo3rTNyQi3FtLTJCIFt8NJtFfuc6/muvjzjNW+955OlAYEpZTyyQkIIhJOwe3Od9Sxde05kupr485DfLFhV+0n1oEGBKWU8snZX6Gssgqv3qB4+Y/crjmtV73qsX1f4ntB+6EBQSmlfDprQGcA2uZkeC4cc1Ze58XZonP6T0+PWLNQ0C474Xrs8NhfIRl0YZpSSvl007h+TBzeg25ts9lfZm2POaBr5Erm6T893XPP5g65Gew4UE6rzGBE6+LUozvyclH8zKg1FbSvX1LAWDQgKKWUT4GA0K2t9Y2+VWaQlyePoH+NgHB0vneWVKdBUTN/k4iVLM+ZmQRw+fAevDhvQ8x6nN43vw61r512GSmlVB2d3LtDeGZRLE9/7yQ+uHl0OCmd10RUJ+GeIy87/nf1BpnOigYEpZRqUGf270SfTq3DLQQRidoZbeLwHhHPM4P+s7gmkwYEpZQ6Av506WAGFbShTXY6lw6Ln9Ji3+GKI1SrSBoQlFLqCDizfyfe/OFppAWEnh1yeWTiYMAai6jpxB7t6JKXxdj+nY5oHXVQWSmlGsE3TjiKrXsOc9XIQgDGHduZD5ZvAyAnI43Pbh8LwMKNu/n7x1/x9uItDV4nbSEopVQjSAsI/3v60eHNdo47qnq2Upkr9cXg7m35yxUn8u9rRzZ4nTQgKKVUE9Aup3q20jE19loAawvQhqZdRkop1QRcOaInlSHDFSf38Nyz+UjQgKCUUk1AMC3ANaN6N24dGvXdlVJK+fb0/5zE/sOVDfb6GhCUUqqZOPOYhp2GWuugsohkicg8EVkkIstE5C67/GURWWj/rBORha5rbhORYhFZKSLnuMqHisgS+9ijYicSF5FM+/WKRWSuiBQm/1aVUkrF46eFUAaMMcbsF5F0YLaITDPGXOacICJ/APbYjwcAE4HjgKOAD0SknzGmCngcmAx8BkwFxgPTgEnALmNMHxGZCNwPhF9fKaVUw6u1hWAs++2n6fZPOBO4/S3/UuBFu+gC4CVjTJkxZi1QDAwXka5AnjFmjrGyPD0HXOi65ln78SvAWKf1oJRS6sjwtQ5BRNLsLqHtwPvGmLmuw6OAbcaY1fbzboA7ufcmu6yb/bhmecQ1xphKrNZGB496TBaRIhEpKikp8VN1pZRSPvkKCMaYKmPMYKAA69v+QNfhy6luHYB3dlcTpzzeNTXr8aQxZpgxZlh+fsPkA1dKqVSV0EplY8xuYCZW3z8iEgS+BbzsOm0T4E7lVwBstssLPMojrrFfsw2wM5G6KaWUqh8/s4zyRaSt/TgbGAessA+PA1YYY9xdQW8BE+2ZQ72AvsA8Y8wWYJ+IjLDHB64C3nRdc7X9+GLgQ2O8dixVSinVUPzMMuoKPCsiaVgBZIox5m372EQiu4swxiwTkSnAl0AlcIM9wwjgOuAZIBtrdtE0u/wp4HkRKcZqGUys8x0ppZSqE2muX8RFpARYX8fLOwKlSaxOc6D3nBr0nlNDfe65pzHGcxC22QaE+hCRImPMsMaux5Gk95wa9J5TQ0Pds6a/VkopBWhAUEopZUvVgPBkY1egEeg9pwa959TQIPeckmMISimloqVqC0EppVQNGhCUUkoBKRgQRGS8vU9DsYjc2tj1SQYR6S4iM0Rkub1nxU/s8vYi8r6IrLb/bOe6xnPPiubGTry4QETetp+36HsWkbYi8oqIrLD/vUemwD3fZP9eLxWRF+09WlrUPYvIP0Rku4gsdZUlfI+x9pzxzRiTMj9AGrAG6A1kAIuAAY1dryTcV1fgRPtxa2AVMAB4ALjVLr8VuN9+PMC+90ygl/13ktbY91HHe78Z+Bfwtv28Rd8zVpr4a+zHGUDblnzPWJmQ1wLZ9vMpwPda2j0Do4ETgaWusoTvEZgHjMRKGDoNODeReqRaC2E4UGyM+coYUw68hLUXQ7NmjNlijPnCfrwPWI71H8m9z8SzRO4/EbVnxRGtdBKISAEwAfi7q7jF3rOI5GF9cDwFYIwpN1bCyRZ7z7YgkG0nvszBSorZou7ZGPMR0Qk9E7rHWvac8SXVAkKsvRpaDHv70SHAXKCzsZIKYv/pbMjaUv4eHgZuAUKuspZ8z72BEuBpu5vs7yKSSwu+Z2PM18BDwAZgC7DHGPNfWvA9uyR6j/H2nPEl1QKCr30XmisRaQW8CtxojNkb71SPsmb19yAi3wC2G2Pm+73Eo6xZ3TPWN+UTgceNMUOAA1hdCbE0+3u2+80vwOoaOQrIFZEr413iUdas7tmHuuw540uqBYRYezU0e/Z+168CLxhjXrOLt9nNSOw/t9vlLeHv4VTgfBFZh9X1N0ZE/knLvudNwCZTvWPhK1gBoiXf8zhgrTGmxBhTAbwGnELLvmdHovcYb88ZX1ItIHwO9BWRXiKSgZVm+61GrlO92TMJngKWG2P+6Drk3mfiaiL3n4jas+JI1TcZjDG3GWMKjDGFWP+OHxpjrqRl3/NWYKOIHGMXjcVKM99i7xmrq2iEiOTYv+djscbIWvI9OxK6RxN/zxl/Gnt0vRFG88/DmoWzBrijseuTpHs6DatpuBhYaP+ch7Uv9XRgtf1ne9c1d9h/BytJcCZCU/sBzqB6llGLvmdgMFBk/1u/AbRLgXu+C2tTrqXA81iza1rUPWPtK7MFqMD6pj+pLvcIDLP/ntYAf8HORuH3R1NXKKWUAlKvy0gppVQMGhCUUkoBGhCUUkrZNCAopZQCNCAopZSyaUBQSikFaEBQSill+38IYlGe7feNRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb9eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_weights_posterior\n",
      "topic_words_posterior\n",
      "predictor$$$0.weight\n",
      "predictor$$$0.bias\n",
      "predictor$$$2.weight\n",
      "predictor$$$2.bias\n",
      "predictor$$$4.weight\n",
      "predictor$$$4.bias\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61aed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bennetthellman/opt/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "news = fetch_20newsgroups(subset='all')\n",
    "vectorizer = CountVectorizer(max_df=0.5, min_df=20, stop_words='english')\n",
    "docs = torch.from_numpy(vectorizer.fit_transform(news['data']).toarray())\n",
    "\n",
    "vocab = pd.DataFrame(columns=['word', 'index'])\n",
    "vocab['word'] = vectorizer.get_feature_names()\n",
    "vocab['index'] = vocab.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc19c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
