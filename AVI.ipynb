{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFqz2KuG9ALG",
    "outputId": "e8855c8d-bab4-4222-e2fe-58277a384949"
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.mcmc import MCMC, HMC, NUTS\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "# import pystan\n",
    "\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "import scipy.stats.kde as kde\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g4kNxQ279CX_"
   },
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.8.1')\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "#smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "55Ur-Emx9I6L"
   },
   "outputs": [],
   "source": [
    "nn_decoder = nn.Sequential(nn.Linear(20, 100), nn.Softplus(), nn.Linear(100, 784), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KDad75Yq9Lh8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AR_D7Xoe9NkP"
   },
   "outputs": [],
   "source": [
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# observation likelihood p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, input_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "\n",
    "        mu = self.fc21(hidden)\n",
    "        sigma = torch.exp(self.fc22(hidden))\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "# define a PyTorch module for the VAE\n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, input_dim,\n",
    "        z_dim=50, hidden_dim=400, use_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = torch.zeros(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            z_scale = torch.ones(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            mu, sigma = self.decoder.forward(z)\n",
    "            print('x size: ', x.shape)\n",
    "            print('mu size: ', mu.shape)\n",
    "#             print('mu_loc size: ', z_loc.shape)\n",
    "#             print('mu_scale size: ', z_scale.shape)\n",
    "            # score against actual images\n",
    "            pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1), obs=x)\n",
    "            # return the loc so we can visualize it later\n",
    "            #return loc_img\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img\n",
    "\n",
    "    def new_instances(self, size=1):\n",
    "         z = stats.norm.rvs(size=(size, self.z_dim))\n",
    "         mu, sigma = self.decoder.forward(torch.as_tensor(z, dtype=torch.float32))\n",
    "         return stats.norm.rvs(mu.data.cpu().numpy(), sigma.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3C-Jsl29PDY",
    "outputId": "725bc1f5-9eec-4e43-d1a6-6fbc1f619e3b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "[epoch 000]  average training loss: 8.8521\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n",
      "x size:  torch.Size([1000, 2])\n",
      "mu size:  torch.Size([1000, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-175dc3a8390a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# do a training epoch over each mini-batch x returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# by the data loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;31m#x = x.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "no_instances = 20000\n",
    "input_dim = 2\n",
    "mu = stats.norm.rvs(size=input_dim)\n",
    "\n",
    "# Generate a positive definite matrix\n",
    "sigma = stats.norm.rvs(size=(input_dim, input_dim))\n",
    "sigma[np.triu_indices(input_dim)] = 0\n",
    "sigma += np.diag(np.abs(stats.norm.rvs(size=input_dim)))\n",
    "sigma = np.matmul(sigma.transpose(), sigma) # inverse cholesky decomposition\n",
    "\n",
    "dataset = stats.multivariate_normal.rvs(mu, sigma, size=no_instances)\n",
    "dataset = torch.as_tensor(dataset, dtype=torch.float32)\n",
    "dataset = TensorDataset(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMKvCl619rU9",
    "outputId": "45b56d09-63fb-4a95-b7a3-5dcf4047ba79"
   },
   "outputs": [],
   "source": [
    "# Generating new instances (replications) from the trained VAE\n",
    "new_instances = vae.new_instances(100000)\n",
    "\n",
    "print(\"True means\")\n",
    "print(mu)\n",
    "print(\"Empirical means of replications:\")\n",
    "print(new_instances.mean(0))\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"True covariance matrix\")\n",
    "print(sigma)\n",
    "print(\"Empirical covariance matrix of replications:\")\n",
    "print(np.cov(new_instances, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "as-FF9CU9tu0"
   },
   "outputs": [],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "data = torch.tensor(np.random.normal(loc=loc, scale=scale, size=1000))\n",
    "dataset = TensorDataset(data)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BivariateAVI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
