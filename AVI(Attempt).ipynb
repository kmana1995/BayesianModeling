{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFqz2KuG9ALG",
    "outputId": "e8855c8d-bab4-4222-e2fe-58277a384949"
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.mcmc import MCMC, HMC, NUTS\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g4kNxQ279CX_"
   },
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.8.1')\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "#smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "55Ur-Emx9I6L"
   },
   "outputs": [],
   "source": [
    "nn_decoder = nn.Sequential(nn.Linear(20, 100), nn.Softplus(), nn.Linear(100, 784), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KDad75Yq9Lh8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.utils import (_sum_rightmost, broadcast_all,\n",
    "                                       lazy_property, tril_matrix_to_vec,\n",
    "                                       vec_to_tril_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "id": "AR_D7Xoe9NkP"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_dim = input_dim\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(input_dim[0]*input_dim[1], hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        val = int((z_dim**2 + z_dim) / 2)\n",
    "#         print(val)\n",
    "        self.fc22 = nn.Linear(hidden_dim, val) # z_dim**2)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x.reshape(x.shape[0], self.input_dim[0] * self.input_dim[1])))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        A_vect = self.fc22(hidden)\n",
    "#         A = A_vect.reshape((A_vect.shape[0], self.z_dim, self.z_dim))\n",
    "#         A = torch.tril(A)\n",
    "        A = vec_to_tril_matrix(A_vect)\n",
    "        z_scale = torch.bmm(A, A.transpose(1, 2))\n",
    "#         z_scale = make_pd_mat(self.z_dim, A_vect)\n",
    "        z_scale.add_(torch.eye(self.z_dim)*1e-4)\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# observation likelihood p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, input_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        mu = self.fc21(hidden)\n",
    "        sigma = torch.exp(self.fc22(hidden))\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "# define a PyTorch module for the VAE\n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, input_dim,\n",
    "        z_dim=5, hidden_dim=250, use_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "        # self.decoder = Decoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, sigma, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        # pyro.module(\"decoder\", self.decoder)\n",
    "        \n",
    "        for i in pyro.plate(\"batch_loop\", x.shape[0]):\n",
    "            \n",
    "            # setup hyperparameters for prior p(z)\n",
    "            mu_loc = torch.zeros(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            mu_scale = torch.eye(x[0].shape[1]).reshape(\n",
    "                (1,x[0].shape[1],x[0].shape[1])).repeat(x.shape[0], 1, 1)\n",
    "            \n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO\n",
    "            mu = pyro.sample(\"latent_{}\".format(i), dist.MultivariateNormal(mu_loc, mu_scale).to_event(1))\n",
    "            scale = pyro.param(\"scale_{}\".format(i), torch.eye(x[0].shape[1]).reshape(\n",
    "                (1,x[0].shape[1],x[0].shape[1])).repeat(x.shape[0], 1, 1))\n",
    "            \n",
    "            with pyro.plate(\"data_loop_{}\".format(i), x.shape[1]):\n",
    "                pyro.sample(\"obs_{}\".format(i), dist.MultivariateNormal(mu[i, :], scale[i, :]),\n",
    "                                obs=x[i, :, :])          \n",
    "            \n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, sigma, x):\n",
    "        \n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        for i in pyro.plate(\"batch_loop\", x.shape[0]):\n",
    "            \n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            \n",
    "#             mu_loc = pyro.param(\"mu_loc_{}\".format(i), z_loc)\n",
    "#             mu_scale = pyro.param(\"mu_scale_{}\".format(i), z_scale)\n",
    "\n",
    "            # sample the latent code z\n",
    "            z = pyro.sample(\"latent_{}\".format(i), dist.MultivariateNormal(z_loc, z_scale).to_event(1))\n",
    "            \n",
    "            scale = pyro.param(\"scale_{}\".format(i), torch.eye(x[0].shape[1]).reshape(\n",
    "                (1,x[0].shape[1],x[0].shape[1])).repeat(x.shape[0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "means = []\n",
    "sigma_mats = []\n",
    "sigma_0s = []\n",
    "for idx in range(100):\n",
    "    random_means = np.random.sample(size=5) \n",
    "    \n",
    "    data, mu_vector, sigma_mat, sigma_mat_0 = multivar_random(5, [1]*5, [0.5,.5,.5,.5], num_samples=50)\n",
    "    X.append(data)\n",
    "    means.append(mu_vector)\n",
    "    sigma_mats.append(sigma_mat)\n",
    "    sigma_0s.append(sigma_mat_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 000]  average training loss: 1527.0283\n",
      "[epoch 005]  average training loss: 876.4451\n",
      "[epoch 010]  average training loss: 742.1348\n",
      "[epoch 015]  average training loss: 724.0627\n",
      "[epoch 020]  average training loss: 684.2909\n",
      "[epoch 025]  average training loss: 662.5758\n",
      "[epoch 030]  average training loss: 664.4851\n",
      "[epoch 035]  average training loss: 639.7789\n",
      "[epoch 040]  average training loss: 633.6171\n",
      "[epoch 045]  average training loss: 646.4437\n",
      "[epoch 050]  average training loss: 646.1480\n",
      "[epoch 055]  average training loss: 610.9302\n",
      "[epoch 060]  average training loss: 610.2170\n",
      "[epoch 065]  average training loss: 620.1910\n",
      "[epoch 070]  average training loss: 621.5195\n",
      "[epoch 075]  average training loss: 619.2721\n",
      "[epoch 080]  average training loss: 630.3494\n",
      "[epoch 085]  average training loss: 615.3012\n",
      "[epoch 090]  average training loss: 637.4810\n",
      "[epoch 095]  average training loss: 632.2919\n",
      "Epoch:  99\r"
     ]
    }
   ],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "no_instances = 20000\n",
    "input_dim = (50, 5)\n",
    "mu = stats.norm.rvs(size=input_dim)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim, z_dim=5)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "train_loader = DataLoader(X, batch_size=100, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "train_elbo = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    print(\"Epoch: \", epoch, end = \"\\r\")\n",
    "    for x in train_loader:\n",
    "        # x = x.cuda()\n",
    "        epoch_loss += svi.step(torch.eye(input_dim[1]), x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 5:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))\n",
    "\n",
    "# NUM_EPOCHS = 1 if smoke_test else 100\n",
    "# TEST_FREQUENCY = 5    \n",
    "        \n",
    "# train_elbo = []\n",
    "# test_elbo = []\n",
    "# # training loop\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     total_epoch_loss_train = train(svi, train_loader, use_cuda=USE_CUDA)\n",
    "#     train_elbo.append(-total_epoch_loss_train)\n",
    "#     print(\"[epoch %03d]  average training loss: %.4f\" % (epoch, total_epoch_loss_train))\n",
    "\n",
    "#     if epoch % TEST_FREQUENCY == 0:\n",
    "#         # report test diagnostics\n",
    "#         total_epoch_loss_test = evaluate(svi, test_loader, use_cuda=USE_CUDA)\n",
    "#         test_elbo.append(-total_epoch_loss_test)\n",
    "#         print(\"[epoch %03d] average test loss: %.4f\" % (epoch, total_epoch_loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'ELBO loss')"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot([i for i in range(len(train_elbo))], train_elbo)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ELBO loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder$$$fc1.weight\n",
      "encoder$$$fc1.bias\n",
      "encoder$$$fc21.weight\n",
      "encoder$$$fc21.bias\n",
      "encoder$$$fc22.weight\n",
      "encoder$$$fc22.bias\n",
      "scale_0\n",
      "scale_1\n",
      "scale_2\n",
      "scale_3\n",
      "scale_4\n",
      "scale_5\n",
      "scale_6\n",
      "scale_7\n",
      "scale_8\n",
      "scale_9\n",
      "scale_10\n",
      "scale_11\n",
      "scale_12\n",
      "scale_13\n",
      "scale_14\n",
      "scale_15\n",
      "scale_16\n",
      "scale_17\n",
      "scale_18\n",
      "scale_19\n",
      "scale_20\n",
      "scale_21\n",
      "scale_22\n",
      "scale_23\n",
      "scale_24\n",
      "scale_25\n",
      "scale_26\n",
      "scale_27\n",
      "scale_28\n",
      "scale_29\n",
      "scale_30\n",
      "scale_31\n",
      "scale_32\n",
      "scale_33\n",
      "scale_34\n",
      "scale_35\n",
      "scale_36\n",
      "scale_37\n",
      "scale_38\n",
      "scale_39\n",
      "scale_40\n",
      "scale_41\n",
      "scale_42\n",
      "scale_43\n",
      "scale_44\n",
      "scale_45\n",
      "scale_46\n",
      "scale_47\n",
      "scale_48\n",
      "scale_49\n",
      "scale_50\n",
      "scale_51\n",
      "scale_52\n",
      "scale_53\n",
      "scale_54\n",
      "scale_55\n",
      "scale_56\n",
      "scale_57\n",
      "scale_58\n",
      "scale_59\n",
      "scale_60\n",
      "scale_61\n",
      "scale_62\n",
      "scale_63\n",
      "scale_64\n",
      "scale_65\n",
      "scale_66\n",
      "scale_67\n",
      "scale_68\n",
      "scale_69\n",
      "scale_70\n",
      "scale_71\n",
      "scale_72\n",
      "scale_73\n",
      "scale_74\n",
      "scale_75\n",
      "scale_76\n",
      "scale_77\n",
      "scale_78\n",
      "scale_79\n",
      "scale_80\n",
      "scale_81\n",
      "scale_82\n",
      "scale_83\n",
      "scale_84\n",
      "scale_85\n",
      "scale_86\n",
      "scale_87\n",
      "scale_88\n",
      "scale_89\n",
      "scale_90\n",
      "scale_91\n",
      "scale_92\n",
      "scale_93\n",
      "scale_94\n",
      "scale_95\n",
      "scale_96\n",
      "scale_97\n",
      "scale_98\n",
      "scale_99\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (fc1): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (fc21): Linear(in_features=250, out_features=5, bias=True)\n",
       "  (fc22): Linear(in_features=250, out_features=15, bias=True)\n",
       "  (softplus): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.3687, 0.4208, 0.3847, 0.4683, 0.3045]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[[ 0.7825,  0.0367,  0.0183,  0.1412,  0.0249],\n",
       "          [ 0.0367,  0.6955,  0.0034, -0.0493,  0.0313],\n",
       "          [ 0.0183,  0.0034,  0.8427, -0.0304,  0.0315],\n",
       "          [ 0.1412, -0.0493, -0.0304,  0.6395, -0.0223],\n",
       "          [ 0.0249,  0.0313,  0.0315, -0.0223,  0.6535]]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=1\n",
    "X[idx].shape\n",
    "vae.encoder.forward(X[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.9149, -0.3758,  0.5495,  2.0860,  2.3146], dtype=torch.float64)"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_posterior_mean_mv_gaussian(50, sigma_mats[idx], sigma_0s[idx], means[idx], X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3019, 0.6804, 0.4994, 0.6828, 0.1597],\n",
       "        [0.6804, 0.2245, 0.1600, 0.2205, 0.0569],\n",
       "        [0.4994, 0.1600, 0.1225, 0.1715, 0.0445],\n",
       "        [0.6828, 0.2205, 0.1715, 0.4210, 0.2461],\n",
       "        [0.1597, 0.0569, 0.0445, 0.2461, 0.2092]], dtype=torch.float64)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_0s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 250]' is invalid for input of size 2500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-875-e64303bb8a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivar_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-866-cc00d28cf598>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# then compute the hidden units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m# then return a mean vector and a (positive) square root covariance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# each of size batch_size x z_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 250]' is invalid for input of size 2500"
     ]
    }
   ],
   "source": [
    "# random_means = np.random.sample(size=5) \n",
    "# x_i, y = multivar_random(5, random_means, [1,1,1,1], num_samples=500)[:2]\n",
    "x_i, mu_vector, sigma, sigma_0 = multivar_random(5, [0] * 5, [.5]*4, 500)\n",
    "\n",
    "vae.encoder.forward(x_i.reshape(1, 500, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mean = get_posterior_mean_mv_gaussian(50, sigma, sigma_0, mu_vector, x_i)\n",
    "post_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sigma = get_posterior_cov_mv_gaussian(50, sigma, sigma_0)\n",
    "post_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to find this exact posterior \n",
    "\n",
    "def get_posterior_cov_mv_gaussian(n, sigma, sigma_0):\n",
    "    sum_part = sigma_0 + 1/n * sigma\n",
    "    sum_part = np.linalg.inv(sum_part)\n",
    "    p1 = np.matmul(sigma_0, sum_part)\n",
    "    p2 = np.matmul(p1, 1/n * sigma)\n",
    "    return(p2)\n",
    "\n",
    "def get_posterior_mean_mv_gaussian(n, sigma, sigma_0, mu_0, data):\n",
    "    sum_part = sigma_0 + 1/n * sigma\n",
    "    sum_part = np.linalg.inv(sum_part)\n",
    "    \n",
    "    middle_part = data.mean(axis=0)\n",
    "    \n",
    "    p1 = np.matmul(sigma_0, sum_part)\n",
    "    p2 = np.matmul(p1, middle_part)\n",
    "    \n",
    "    p3 = np.matmul(1/n * sigma, sum_part)\n",
    "    p4 = np.matmul(p3, mu_0)\n",
    "    return(p2 + p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivar_random(size, normal_params, gamma_params, num_samples):   \n",
    "\n",
    "    # simulate two random covariance matrices (PSD) for sigma and sigma_0\n",
    "    mat = np.random.gamma(gamma_params[0], gamma_params[1], size=size**2).reshape((size, size))\n",
    "    sigma_mat = torch.tensor(np.dot(mat, mat.transpose()))\n",
    "    \n",
    "    mat_0 = np.random.gamma(gamma_params[2], gamma_params[3], size=size**2).reshape((size, size))\n",
    "    sigma_mat_0 = torch.tensor(np.dot(mat_0, mat_0.transpose()))\n",
    "    \n",
    "    # simulate some random means\n",
    "    mu_vector = torch.tensor(np.random.multivariate_normal(normal_params, sigma_mat_0, size=1))[0]\n",
    "\n",
    "    # now simulate multivariate gaussian\n",
    "    data = torch.tensor(np.random.multivariate_normal(mu_vector, sigma_mat, size=num_samples).astype(\"float32\"))\n",
    "    \n",
    "    return(data, mu_vector, sigma_mat, sigma_mat_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-05ed183301c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3C-Jsl29PDY",
    "outputId": "725bc1f5-9eec-4e43-d1a6-6fbc1f619e3b"
   },
   "outputs": [],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "no_instances = 20000\n",
    "input_dim = 2\n",
    "mu = stats.norm.rvs(size=input_dim)\n",
    "\n",
    "# Generate a positive definite matrix\n",
    "sigma = stats.norm.rvs(size=(input_dim, input_dim))\n",
    "sigma[np.triu_indices(input_dim)] = 0\n",
    "sigma += np.diag(np.abs(stats.norm.rvs(size=input_dim)))\n",
    "sigma = np.matmul(sigma.transpose(), sigma) # inverse cholesky decomposition\n",
    "\n",
    "dataset = stats.multivariate_normal.rvs(mu, sigma, size=no_instances)\n",
    "dataset = torch.as_tensor(dataset, dtype=torch.float32)\n",
    "dataset = TensorDataset(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim, z_dim=2)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3b93b1e6f520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigma' is not defined"
     ]
    }
   ],
   "source": [
    "test = stats.multivariate_normal.rvs(mu, sigma, size=no_instances)\n",
    "test = torch.as_tensor(test, dtype=torch.float32)\n",
    "vae.encoder(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMKvCl619rU9",
    "outputId": "45b56d09-63fb-4a95-b7a3-5dcf4047ba79"
   },
   "outputs": [],
   "source": [
    "# Generating new instances (replications) from the trained VAE\n",
    "new_instances = vae.new_instances(100000)\n",
    "\n",
    "print(\"True means\")\n",
    "print(mu)\n",
    "print(\"Empirical means of replications:\")\n",
    "print(new_instances.mean(0))\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"True covariance matrix\")\n",
    "print(sigma)\n",
    "print(\"Empirical covariance matrix of replications:\")\n",
    "print(np.cov(new_instances, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "as-FF9CU9tu0"
   },
   "outputs": [],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "loc = 5\n",
    "scale = 20\n",
    "data = torch.tensor(np.random.normal(loc=loc, scale=scale, size=1000))\n",
    "dataset = TensorDataset(data)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BivariateAVI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
