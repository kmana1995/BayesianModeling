{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFqz2KuG9ALG",
    "outputId": "e8855c8d-bab4-4222-e2fe-58277a384949"
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.mcmc import MCMC, HMC, NUTS\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g4kNxQ279CX_"
   },
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.8.1')\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "# Enable smoke test - run the notebook cells on CI.\n",
    "#smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "55Ur-Emx9I6L"
   },
   "outputs": [],
   "source": [
    "nn_decoder = nn.Sequential(nn.Linear(20, 100), nn.Softplus(), nn.Linear(100, 784), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KDad75Yq9Lh8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AR_D7Xoe9NkP"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# define the PyTorch module that parameterizes the\n",
    "# diagonal gaussian distribution q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.input_dim = input_dim\n",
    "        # setup the three linear transformations used\n",
    "        self.fc1 = nn.Linear(input_dim[0]*input_dim[1], hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim**2)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # then compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(x.reshape(x.shape[0], self.input_dim[0] * self.input_dim[1])))\n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        A_vect = self.fc22(hidden)\n",
    "        A = A_vect.reshape((A_vect.shape[0], self.z_dim, self.z_dim))\n",
    "        A = torch.tril(A, diagonal=0)\n",
    "        for idx in range(5):\n",
    "            A[:,idx, idx] = torch.exp(A[:,idx, idx])\n",
    "        try:\n",
    "            torch.cholesky(z_scale)\n",
    "            z_scale = torch.bmm(A, A.transpose(1, 2))\n",
    "            return z_loc, z_scale\n",
    "        except:\n",
    "            for idx in range(A.shape[0]):\n",
    "                try:\n",
    "                    z_scale = torch.bmm(A[idx,:,:], A[idx,:,:].transpose(1, 2))\n",
    "                    torch.cholesky(z_scale)\n",
    "                except:\n",
    "                    laplace = 1e-9\n",
    "                    while True:\n",
    "                        for v_idx in range(5):\n",
    "                            for h_idx in range(5):\n",
    "                                if v_idx < h_idx:\n",
    "                                    continue\n",
    "                                try:\n",
    "                                    A_c = A[idx,:,:]\n",
    "                                    A_c[v_idx, h_idx] += 1e-9\n",
    "                                    z_scale = torch.bmm(A_c, A_c.transpose(1, 2))\n",
    "                                    torch.cholesky(z_scale)\n",
    "                                    A[idx,:,:] = A_c\n",
    "                                    break\n",
    "                                except:\n",
    "                                    laplace += 1\n",
    "                                    continue\n",
    "                            break\n",
    "                        break\n",
    "        z_scale = torch.bmm(A, A.transpose(1, 2))              \n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "# define the PyTorch module that parameterizes the\n",
    "# observation likelihood p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, input_dim)\n",
    "        # setup the non-linearities\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # define the forward computation on the latent z\n",
    "        # first compute the hidden units\n",
    "        hidden = self.softplus(self.fc1(z))\n",
    "        mu = self.fc21(hidden)\n",
    "        sigma = torch.exp(self.fc22(hidden))\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "# define a PyTorch module for the VAE\n",
    "class VAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, input_dim,\n",
    "        z_dim=5, hidden_dim=250, use_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = Encoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "        # self.decoder = Decoder(z_dim, hidden_dim, input_dim=input_dim)\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, sigma, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        # pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            mu_loc = torch.zeros(x.shape[0], self.z_dim, dtype=x.dtype, device=x.device)\n",
    "            mu_scale = torch.eye(x[0].shape[1]).reshape(\n",
    "                (1,x[0].shape[1],x[0].shape[1])).repeat(x.shape[0], 1, 1)\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO\n",
    "            # print(\"Dimension of mu_scale {}\".format(mu_scale.shape))\n",
    "            # print(\"Dimension of mu_loc {}\".format(mu_loc.shape))\n",
    "            mu = pyro.sample(\"latent\", dist.MultivariateNormal(mu_loc, mu_scale))\n",
    "            # print(\"Dimension of mu {}\".format(mu.shape))\n",
    "            # score against actual images\n",
    "            # print(x.shape)\n",
    "            pyro.sample(\"obs\", dist.MultivariateNormal(mu, sigma), obs=x.mean())\n",
    "            # print(\"Here\")\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, sigma, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            # print(z_loc.shape)\n",
    "            # print(z_scale.shape)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.MultivariateNormal(z_loc, z_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for idx in range(100):\n",
    "    random_means = np.random.sample(size=5) \n",
    "    \n",
    "    x_i = multivar_random(5, random_means, [1,1,1,1], num_samples=500)[0]\n",
    "    X.append(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kylea\\Miniconda3\\envs\\devenv\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6515e+00, -3.1009e+00, -2.0017e+00, -1.4382e+01, -2.8855e-01],\n",
       "        [-3.9868e-01, -1.7197e+00, -1.9020e+00, -7.9675e+00, -9.8578e+00],\n",
       "        [-4.3851e-01, -5.0679e+00, -2.9041e+00, -8.5794e+00, -1.2251e+00],\n",
       "        ...,\n",
       "        [-5.3434e-01, -2.9726e+00, -1.0164e+00, -1.1418e+01, -7.0515e+00],\n",
       "        [-2.5917e+00, -8.9148e-01, -2.2809e+00, -1.6618e+01, -8.8463e-01],\n",
       "        [-1.4421e+01, -1.8586e+01, -1.8143e+01, -2.5163e+01, -5.9605e-07]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.Tensor([0] * 100)\n",
    "sd = torch.Tensor([1] * 100)\n",
    "\n",
    "p = torch.distributions.Normal(mu,sd)\n",
    "q = torch.distributions.Normal(mu,sd)\n",
    "\n",
    "out = torch.distributions.kl_divergence(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([100]), scale: torch.Size([100]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8712765382046728"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "np.log(norm.pdf(x=1.846, loc=0.4659, scale=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "no_instances = 20000\n",
    "input_dim = (500, 5)\n",
    "mu = stats.norm.rvs(size=input_dim)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim, z_dim=5)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "train_loader = DataLoader(X, batch_size=50, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x in train_loader:\n",
    "        # x = x.cuda()\n",
    "        epoch_loss += svi.step(torch.eye(5), x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success, removed 0.0036956\n",
      "Success, removed 3.1744\n",
      "Success, removed 2.9765\n",
      "Success, removed 0.026687\n"
     ]
    }
   ],
   "source": [
    "L = np.array([[ 3.6956e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
    "        [ 1.0094e-01,  1.0461e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
    "        [ 3.1744e+00,  2.9765e+00,  2.6687e-02,  0.0000e+00,  0.0000e+00],\n",
    "        [-6.0710e+00,  4.9560e-03,  2.6047e+00,  1.4794e-01,  0.0000e+00],\n",
    "        [ 1.4442e+00, -1.7773e+00,  4.8894e-01, -1.9205e+00,  2.4491e-05]])\n",
    "for v_idx in range(5):\n",
    "    for h_idx in range(5):\n",
    "        if v_idx < h_idx:\n",
    "            continue\n",
    "        try:\n",
    "            L_c = L.copy()\n",
    "            L_c[v_idx, h_idx] += 1e-9\n",
    "            np.linalg.cholesky(np.dot(L_c, L_c.T))\n",
    "            print(\"Success, removed {}\".format(L[v_idx, h_idx]))\n",
    "        except:\n",
    "            None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.005337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>109.442710</td>\n",
       "      <td>31.457590</td>\n",
       "      <td>-0.560962</td>\n",
       "      <td>-18.446558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011731</td>\n",
       "      <td>31.457590</td>\n",
       "      <td>18.937080</td>\n",
       "      <td>-19.187519</td>\n",
       "      <td>-0.692617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022436</td>\n",
       "      <td>-0.560962</td>\n",
       "      <td>-19.187519</td>\n",
       "      <td>43.663414</td>\n",
       "      <td>-7.787123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005337</td>\n",
       "      <td>-18.446558</td>\n",
       "      <td>-0.692617</td>\n",
       "      <td>-7.787123</td>\n",
       "      <td>9.171892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1          2          3          4\n",
       "0  0.000014    0.000373   0.011731  -0.022436   0.005337\n",
       "1  0.000373  109.442710  31.457590  -0.560962 -18.446558\n",
       "2  0.011731   31.457590  18.937080 -19.187519  -0.692617\n",
       "3 -0.022436   -0.560962 -19.187519  43.663414  -7.787123\n",
       "4  0.005337  -18.446558  -0.692617  -7.787123   9.171892"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.dot(L, L.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Matrix is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12084\\1192191561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;33m[\u001b[0m \u001b[1;36m1.1731e-02\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m3.1456e+01\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m1.8937e+01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.9187e+01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6.9259e-01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2.2436e-02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m5.6098e-01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.9187e+01\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m4.3663e+01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m7.7871e+00\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         [ 5.3372e-03, -1.8445e+01, -6.9259e-01, -7.7871e+00,  9.1720e+00]])\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcholesky\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\devenv\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mcholesky\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\devenv\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Matrix is not positive definite\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_eigenvalues_nonconvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Matrix is not positive definite"
     ]
    }
   ],
   "source": [
    "np.linalg.cholesky([[ 1.3657e-05,  3.7304e-04,  1.1731e-02, -2.2436e-02,  5.3372e-03],\n",
    "        [ 3.7304e-04,  1.0943e+02,  3.1456e+01, -5.6098e-01, -1.8445e+01],\n",
    "        [ 1.1731e-02,  3.1456e+01,  1.8937e+01, -1.9187e+01, -6.9259e-01],\n",
    "        [-2.2436e-02, -5.6098e-01, -1.9187e+01,  4.3663e+01, -7.7871e+00],\n",
    "        [ 5.3372e-03, -1.8445e+01, -6.9259e-01, -7.7871e+00,  9.1720e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "cov1 = torch.eye(3)\n",
    "cov2 = torch.Tensor([[1, 1, 1], [1, 2, 2], [1, 2, 3]])\n",
    "cov = torch.stack([cov1, cov2], 0)\n",
    "distrib = dist.MultivariateNormal(loc=mean, covariance_matrix=cov)\n",
    "distrib.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivar_random(size, normal_params, gamma_params, num_samples):   \n",
    "\n",
    "    # simulate two random covariance matrices (PSD) for sigma and sigma_0\n",
    "    mat = np.random.gamma(gamma_params[0], gamma_params[1], size=size**2).reshape((size, size))\n",
    "    sigma_mat = torch.tensor(np.dot(mat, mat.transpose()))\n",
    "    \n",
    "    mat_0 = np.random.gamma(gamma_params[2], gamma_params[3], size=size**2).reshape((size, size))\n",
    "    sigma_mat_0 = torch.tensor(np.dot(mat_0, mat_0.transpose()))\n",
    "    \n",
    "    # simulate some random means\n",
    "    mu_vector = torch.tensor(np.random.multivariate_normal(normal_params, sigma_mat_0, size=1))[0]\n",
    "\n",
    "    # now simulate multivariate gaussian\n",
    "    data = torch.tensor(np.random.multivariate_normal(mu_vector, sigma_mat, size=num_samples).astype(\"float32\"))\n",
    "    \n",
    "    return(data, mu_vector, sigma_mat, sigma_mat_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3C-Jsl29PDY",
    "outputId": "725bc1f5-9eec-4e43-d1a6-6fbc1f619e3b"
   },
   "outputs": [],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "\n",
    "no_instances = 20000\n",
    "input_dim = 2\n",
    "mu = stats.norm.rvs(size=input_dim)\n",
    "\n",
    "# Generate a positive definite matrix\n",
    "sigma = stats.norm.rvs(size=(input_dim, input_dim))\n",
    "sigma[np.triu_indices(input_dim)] = 0\n",
    "sigma += np.diag(np.abs(stats.norm.rvs(size=input_dim)))\n",
    "sigma = np.matmul(sigma.transpose(), sigma) # inverse cholesky decomposition\n",
    "\n",
    "dataset = stats.multivariate_normal.rvs(mu, sigma, size=no_instances)\n",
    "dataset = torch.as_tensor(dataset, dtype=torch.float32)\n",
    "dataset = TensorDataset(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim, z_dim=2)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19576\\3212623320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigma' is not defined"
     ]
    }
   ],
   "source": [
    "test = stats.multivariate_normal.rvs(mu, sigma, size=no_instances)\n",
    "test = torch.as_tensor(test, dtype=torch.float32)\n",
    "vae.encoder(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMKvCl619rU9",
    "outputId": "45b56d09-63fb-4a95-b7a3-5dcf4047ba79"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VAE' object has no attribute 'new_instances'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19576\\2491400002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Generating new instances (replications) from the trained VAE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_instances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_instances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"True means\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\devenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m-> 1186\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VAE' object has no attribute 'new_instances'"
     ]
    }
   ],
   "source": [
    "# Generating new instances (replications) from the trained VAE\n",
    "new_instances = vae.new_instances(100000)\n",
    "\n",
    "print(\"True means\")\n",
    "print(mu)\n",
    "print(\"Empirical means of replications:\")\n",
    "print(new_instances.mean(0))\n",
    "\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"True covariance matrix\")\n",
    "print(sigma)\n",
    "print(\"Empirical covariance matrix of replications:\")\n",
    "print(np.cov(new_instances, rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "as-FF9CU9tu0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# clear param store\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pyro\u001b[38;5;241m.\u001b[39mclear_param_store()\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(loc\u001b[38;5;241m=\u001b[39m\u001b[43mloc\u001b[49m, scale\u001b[38;5;241m=\u001b[39mscale, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(data)\n\u001b[0;32m      5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m      num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loc' is not defined"
     ]
    }
   ],
   "source": [
    "# clear param store\n",
    "pyro.clear_param_store()\n",
    "loc = 5\n",
    "scale = 20\n",
    "data = torch.tensor(np.random.normal(loc=loc, scale=scale, size=1000))\n",
    "dataset = TensorDataset(data)\n",
    "train_loader = DataLoader(dataset, batch_size=1000, shuffle=True,\n",
    "     num_workers=1, pin_memory=True, drop_last=False)\n",
    "\n",
    "# setup the VAE\n",
    "vae = VAE(use_cuda=False, input_dim=input_dim)\n",
    "\n",
    "adam_args = {\"lr\": 0.001}\n",
    "optimizer = Adam(adam_args)\n",
    "\n",
    "# setup the inference algorithm\n",
    "svi = SVI(vae.model, vae.guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "train_elbo = []\n",
    "for epoch in range(100):\n",
    "    # initialize loss accumulator\n",
    "    epoch_loss = 0.\n",
    "    # do a training epoch over each mini-batch x returned\n",
    "    # by the data loader\n",
    "    for x, in train_loader:\n",
    "        #x = x.cuda()\n",
    "        epoch_loss += svi.step(x)\n",
    "\n",
    "    # report training diagnostics\n",
    "    if not epoch % 10:\n",
    "        normalizer_train = len(train_loader.dataset)\n",
    "        total_epoch_loss_train = epoch_loss / normalizer_train\n",
    "        train_elbo.append(total_epoch_loss_train)\n",
    "        print(\"[epoch %03d]  average training loss: %.4f\" %\n",
    "             (epoch, total_epoch_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BivariateAVI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
